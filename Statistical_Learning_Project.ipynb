{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean MSE for our Dataset is: 0.11461647597580019\n",
      "             feature  importance\n",
      "21               PPE    0.147481\n",
      "18           spread1    0.111556\n",
      "0        MDVP:Fo(Hz)    0.092874\n",
      "2       MDVP:Flo(Hz)    0.065176\n",
      "19           spread2    0.055777\n",
      "1       MDVP:Fhi(Hz)    0.052304\n",
      "7         Jitter:DDP    0.041746\n",
      "11      Shimmer:APQ5    0.038052\n",
      "20                D2    0.036167\n",
      "16              RPDE    0.034268\n",
      "5           MDVP:RAP    0.033910\n",
      "14               NHR    0.032748\n",
      "17               DFA    0.031814\n",
      "4   MDVP:Jitter(Abs)    0.030544\n",
      "8       MDVP:Shimmer    0.029405\n",
      "12          MDVP:APQ    0.029205\n",
      "15               HNR    0.026468\n",
      "9   MDVP:Shimmer(dB)    0.024679\n",
      "13       Shimmer:DDA    0.023336\n",
      "10      Shimmer:APQ3    0.022472\n",
      "3     MDVP:Jitter(%)    0.020044\n",
      "6           MDVP:PPQ    0.019974\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "ParkinDF = pd.read_csv(\"C:/Users/blueg/Desktop/Stat learning Project/parkinsons.data\")\n",
    "\n",
    "ParkinDF = ParkinDF.iloc[: , 1:]\n",
    "# Extract the features and target variable\n",
    "x = ParkinDF.drop(['status'], axis=1)\n",
    "y = ParkinDF['status']\n",
    "\n",
    "# Initialize the LOOCV object\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Initialize an empty list to store the MSEs\n",
    "mse_list = []\n",
    "\n",
    "# Loop through each data point\n",
    "for train_index, test_index in loo.split(x):\n",
    "    # Split the data into training and test sets\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "# Compute the mean MSE\n",
    "mean_mse = sum(mse_list) / len(mse_list)\n",
    "print('The Mean MSE for our Dataset is:', mean_mse)\n",
    "\n",
    "# Separate the features and target variable\n",
    "x = ParkinDF.drop(['status'], axis=1)\n",
    "y = ParkinDF['status']\n",
    "\n",
    "# Initialize a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=len(x_train), random_state=42)\n",
    "\n",
    "# Fit the classifier on the data\n",
    "rf.fit(x, y)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a dataframe of feature importances\n",
    "feature_importances = pd.DataFrame({'feature': x.columns, 'importance': importances})\n",
    "\n",
    "# Sort the dataframe by feature importance in descending order\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances)\n",
    "\n",
    "plt.bar([x for x in range(len(importances))], importances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Accuracy for our Dataset is: 0.8512820512820513\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ParkinDF = pd.read_csv(\"C:/Users/blueg/Desktop/Stat learning Project/parkinsons.data\")\n",
    "\n",
    "ParkinDF = ParkinDF.iloc[: , 1:]\n",
    "# Extract the features and target variable\n",
    "x = ParkinDF.drop(['status'], axis=1)\n",
    "y = ParkinDF['status']\n",
    "\n",
    "# Initialize the LOOCV object\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Convert continuous target variable to binary\n",
    "y_binary = np.where(y > 0, 1, 0)\n",
    "\n",
    "# Initialize an empty list to store the accuracies\n",
    "accuracy_list = []\n",
    "\n",
    "# Loop through each data point\n",
    "for train_index, test_index in loo.split(x):\n",
    "    # Split the data into training and test sets\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y_binary[train_index], y_binary[test_index]\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "# Compute the mean accuracy\n",
    "mean_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print('The Mean Accuracy for our Dataset is:', mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Accuracy for our Dataset is: 0.8512820512820513\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "ParkinDF = pd.read_csv(\"C:/Users/blueg/Desktop/Stat learning Project/parkinsons.data\")\n",
    "\n",
    "# Extract the features and target variable\n",
    "X = ParkinDF.iloc[:, 1:]  # All features\n",
    "y = ParkinDF['status']\n",
    "\n",
    "# Select 5 features\n",
    "selected_features = ['PPE', 'spread1', 'MDVP:Fo(Hz)', 'MDVP:Flo(Hz)', 'spread2']\n",
    "X = X[selected_features]\n",
    "\n",
    "# Initialize the LOOCV object\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Initialize an empty list to store the accuracies\n",
    "accuracy_list = []\n",
    "\n",
    "# Loop through each data point\n",
    "for train_index, test_index in loo.split(X):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "# Compute the mean accuracy\n",
    "mean_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print('The Mean Accuracy for our Dataset is:', mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>174.188</td>\n",
       "      <td>230.978</td>\n",
       "      <td>94.261</td>\n",
       "      <td>0.00459</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.00790</td>\n",
       "      <td>0.04087</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07008</td>\n",
       "      <td>0.02764</td>\n",
       "      <td>19.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448439</td>\n",
       "      <td>0.657899</td>\n",
       "      <td>-6.538586</td>\n",
       "      <td>0.121952</td>\n",
       "      <td>2.657476</td>\n",
       "      <td>0.133050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>209.516</td>\n",
       "      <td>253.017</td>\n",
       "      <td>89.488</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.02751</td>\n",
       "      <td>0.263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04812</td>\n",
       "      <td>0.01810</td>\n",
       "      <td>19.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431674</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>-6.195325</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>2.784312</td>\n",
       "      <td>0.168895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>174.688</td>\n",
       "      <td>240.005</td>\n",
       "      <td>74.287</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>0.256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.10715</td>\n",
       "      <td>17.883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.655683</td>\n",
       "      <td>-6.787197</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>2.679772</td>\n",
       "      <td>0.131728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>198.764</td>\n",
       "      <td>396.961</td>\n",
       "      <td>74.904</td>\n",
       "      <td>0.00740</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.02296</td>\n",
       "      <td>0.241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.07223</td>\n",
       "      <td>19.020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>-6.744577</td>\n",
       "      <td>0.207454</td>\n",
       "      <td>2.138608</td>\n",
       "      <td>0.123306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>214.289</td>\n",
       "      <td>260.277</td>\n",
       "      <td>77.973</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.01884</td>\n",
       "      <td>0.190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>21.209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>-5.724056</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>2.555477</td>\n",
       "      <td>0.148569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)   \n",
       "0        119.992       157.302        74.997         0.00784  \\\n",
       "1        122.400       148.650       113.819         0.00968   \n",
       "2        116.682       131.111       111.555         0.01050   \n",
       "3        116.676       137.871       111.366         0.00997   \n",
       "4        116.014       141.781       110.655         0.01284   \n",
       "..           ...           ...           ...             ...   \n",
       "190      174.188       230.978        94.261         0.00459   \n",
       "191      209.516       253.017        89.488         0.00564   \n",
       "192      174.688       240.005        74.287         0.01360   \n",
       "193      198.764       396.961        74.904         0.00740   \n",
       "194      214.289       260.277        77.973         0.00567   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer   \n",
       "0             0.00007   0.00370   0.00554     0.01109       0.04374  \\\n",
       "1             0.00008   0.00465   0.00696     0.01394       0.06134   \n",
       "2             0.00009   0.00544   0.00781     0.01633       0.05233   \n",
       "3             0.00009   0.00502   0.00698     0.01505       0.05492   \n",
       "4             0.00011   0.00655   0.00908     0.01966       0.06425   \n",
       "..                ...       ...       ...         ...           ...   \n",
       "190           0.00003   0.00263   0.00259     0.00790       0.04087   \n",
       "191           0.00003   0.00331   0.00292     0.00994       0.02751   \n",
       "192           0.00008   0.00624   0.00564     0.01873       0.02308   \n",
       "193           0.00004   0.00370   0.00390     0.01109       0.02296   \n",
       "194           0.00003   0.00295   0.00317     0.00885       0.01884   \n",
       "\n",
       "     MDVP:Shimmer(dB)  ...  Shimmer:DDA      NHR     HNR  status      RPDE   \n",
       "0               0.426  ...      0.06545  0.02211  21.033       1  0.414783  \\\n",
       "1               0.626  ...      0.09403  0.01929  19.085       1  0.458359   \n",
       "2               0.482  ...      0.08270  0.01309  20.651       1  0.429895   \n",
       "3               0.517  ...      0.08771  0.01353  20.644       1  0.434969   \n",
       "4               0.584  ...      0.10470  0.01767  19.649       1  0.417356   \n",
       "..                ...  ...          ...      ...     ...     ...       ...   \n",
       "190             0.405  ...      0.07008  0.02764  19.517       0  0.448439   \n",
       "191             0.263  ...      0.04812  0.01810  19.147       0  0.431674   \n",
       "192             0.256  ...      0.03804  0.10715  17.883       0  0.407567   \n",
       "193             0.241  ...      0.03794  0.07223  19.020       0  0.451221   \n",
       "194             0.190  ...      0.03078  0.04398  21.209       0  0.462803   \n",
       "\n",
       "          DFA   spread1   spread2        D2       PPE  \n",
       "0    0.815285 -4.813031  0.266482  2.301442  0.284654  \n",
       "1    0.819521 -4.075192  0.335590  2.486855  0.368674  \n",
       "2    0.825288 -4.443179  0.311173  2.342259  0.332634  \n",
       "3    0.819235 -4.117501  0.334147  2.405554  0.368975  \n",
       "4    0.823484 -3.747787  0.234513  2.332180  0.410335  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "190  0.657899 -6.538586  0.121952  2.657476  0.133050  \n",
       "191  0.683244 -6.195325  0.129303  2.784312  0.168895  \n",
       "192  0.655683 -6.787197  0.158453  2.679772  0.131728  \n",
       "193  0.643956 -6.744577  0.207454  2.138608  0.123306  \n",
       "194  0.664357 -5.724056  0.190667  2.555477  0.148569  \n",
       "\n",
       "[195 rows x 23 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "ParkinDF.head(195)\n",
    "\n",
    "#logit_model = sm.Logit(y,X)\n",
    "#result = logit_model.fit()\n",
    "#print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
